'''
Q1
Build a multi-layer neural network using PyTorch. Use it to solve the XOR
classification problem generated by gen_xor.py. Visualize the decision
surface using matplotlib, with the training data overlaid as in Tensorflow
Playground.
'''
import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

torch.manual_seed(2)

class NN(nn.Module):
    def __init__(self, params={input_dim:2, output_dim:2}):
        super(NN, self).__init__()
        self.l1 = nn.Linear(params[input_dim], 2)
        self.l2 = nn.Linear(params[output_dim, 2)
        self.loss_func = nn.MSELoss()
        self.optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)
    
    def forward(self, x):
        x = self.l2(func.sigmoid(self.l1(x)))
        return x
    

network


    def train(train_X, train_Y, params={optimizer: 'SGD', epochs: 2000, learning_rate=0.01}):
        m = globals()['optim']()
        opt = getattr(m, 'SGD')
        opt = opt(self.parameters, learning_rate)
        train_data = [(train_X[i], train_Y[i]) for i in range(0, len(train_X))]
        for e in range(0, epochs):
            for x, y in train_data:
                opt.zero_grad()
                

# Call it
func()


'''
Q2
Implement a feed-forward neural network function from scratch. Extract the
learned weights from Q1 and run the model through your custom implementation.
Demonstrate that you get the same results.
Do not train the model yourself. Do not implement backpropagation. Just
run it forward using the PyTorch-trained weights.
'''