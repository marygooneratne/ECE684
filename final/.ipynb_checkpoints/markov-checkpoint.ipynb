{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "sample_data = pd.read_csv(\"data/sample.csv\")\n",
    "author_df = pd.DataFrame(train_data)[\"author\"]\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "CHAR_ALLOW = [ \" \"]\n",
    "ALPHA_ALLOW = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\",\n",
    "                       \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\",\"z\", \"รถ\"]\n",
    "DF = train_df[0:500]\n",
    "TEST_DF = train_df[501:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_char(char):\n",
    "    char = char.lower()\n",
    "    if char.isnumeric():\n",
    "        return \" \"\n",
    "    if char.isalpha():\n",
    "        if char in ALPHA_ALLOW:\n",
    "            return char\n",
    "        else: return \"รถ\"\n",
    "    else: return \" \"\n",
    "\n",
    "def process_text(text):\n",
    "    cleaned = \"\"\n",
    "    for c in text:\n",
    "        cleaned += process_char(c)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = set()\n",
    "for i, r in DF.iterrows():\n",
    "    new = process_text(r[\"text\"])\n",
    "    new = new.split(\" \")\n",
    "    WORDS.update(new)\n",
    "WORDS = list(WORDS)\n",
    "WORD_TO_IDX = {}\n",
    "IDX_TO_WORD = {}\n",
    "for index, word in enumerate(WORDS):\n",
    "    WORD_TO_IDX[word] = index\n",
    "    IDX_TO_WORD[index] = word\n",
    "LEN_WORDS = len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(text):\n",
    "    t = np.zeros((LEN_WORDS, LEN_WORDS))\n",
    "    text = text.split(\" \")\n",
    "    for i in range(len(text)-1):\n",
    "        curr_word = text[i]\n",
    "        curr_idx = WORD_TO_IDX[curr_word]\n",
    "        next_word = text[i+1]\n",
    "        next_idx = WORD_TO_IDX[next_word]\n",
    "        t[curr_idx][next_idx] += 1\n",
    "    \n",
    "    row_sums = np.sum(t, 1)\n",
    "    \n",
    "    for i in range(LEN_WORDS):\n",
    "        row_sum = row_sums[i]\n",
    "        if(row_sum == 0):\n",
    "            row_sum = 1\n",
    "        t[i, :] = t[i, :]/row_sum\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix_by_author(df):\n",
    "    text_by_author = {}\n",
    "    for index, row in df.iterrows():\n",
    "        author = row[\"author\"]\n",
    "        text = process_text(row[\"text\"])\n",
    "        if author not in text_by_author.keys():\n",
    "            text_by_author[author] = \"\"\n",
    "        text_by_author[author] = text_by_author[author] + text\n",
    "    data = []\n",
    "    for author in text_by_author.keys():\n",
    "        d = {\"author\": author, \"text\": text_by_author[author], \"transition_matrix\": transition_matrix(text_by_author[author])}\n",
    "        data.append(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(matrix, text):\n",
    "    text = process_text(text).split(\" \")\n",
    "    len_text = len(text) \n",
    "    log_likelihood = np.zeros(0)\n",
    "    for i in range(0, len(text)-1):\n",
    "        current_word = text[i]\n",
    "        next_word = text[i+1]\n",
    "        step_prob = 0\n",
    "        if current_word in WORD_TO_IDX.keys() and next_word in WORD_TO_IDX.keys():\n",
    "            step_prob = matrix[WORD_TO_IDX[current_word] , WORD_TO_IDX[next_word]]    \n",
    "        log_likelihood = np.append(log_likelihood, step_prob) \n",
    "\n",
    "    log_likelihood = np.log(log_likelihood)\n",
    "    likelihood_neglect_special_case = 0\n",
    "    inf_count = 0\n",
    "\n",
    "    for i in range(len(log_likelihood)):\n",
    "        if (log_likelihood[i]!= float(\"-inf\")):\n",
    "            likelihood_neglect_special_case = likelihood_neglect_special_case+log_likelihood[i] \n",
    "        else:\n",
    "            inf_count = inf_count+1 \n",
    "\n",
    "    log_likelihood_acc = np.where(log_likelihood == float(\"-inf\"), 0,  log_likelihood)\n",
    "    log_likelihood_acc = np.cumsum(log_likelihood_acc)\n",
    "    return likelihood_neglect_special_case/(len_text-inf_count), log_likelihood_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author:  EAP , log likelihood:  (-1.6700258686722194, array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -1.88569129, -1.88569129, -1.88569129, -1.88569129, -1.88569129,\n",
      "       -1.88569129, -1.88569129, -1.88569129, -6.16927785, -6.16927785,\n",
      "       -6.68010347, -6.68010347, -6.68010347, -6.68010347, -6.68010347,\n",
      "       -6.68010347]))\n",
      "author:  HPL , log likelihood:  (-2.0317292866564696, array([  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,  -1.58696506,  -1.58696506,  -1.58696506,\n",
      "        -1.58696506,  -1.58696506,  -1.58696506,  -1.58696506,\n",
      "        -1.58696506,  -6.06430187,  -8.36688696,  -8.36688696,\n",
      "       -10.15864643, -10.15864643, -10.15864643, -10.15864643,\n",
      "       -10.15864643]))\n",
      "author:  MWS , log likelihood:  (-2.091531996161097, array([  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.        ,  -1.59263079,  -1.59263079,  -1.59263079,\n",
      "        -1.59263079,  -5.28151025,  -5.28151025,  -5.28151025,\n",
      "        -5.28151025,  -9.35904769,  -9.35904769, -10.45765998,\n",
      "       -10.45765998, -10.45765998, -10.45765998, -10.45765998,\n",
      "       -10.45765998]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def predict_author(text, matrices):\n",
    "    min_val = -10000000000\n",
    "    author = \"\"\n",
    "    for d in data:\n",
    "        t = d[\"transition_matrix\"]\n",
    "        likelikhood = log_likelihood(t, text)[1]\n",
    "        if likelihood > min_val:\n",
    "            min_val = likelihood\n",
    "            author = d[\"author\"]\n",
    "            \n",
    "    return {\"author\": author, \"likelihood\": min_val}\n",
    "    \n",
    "\n",
    "def test(df, matrices):\n",
    "    count = len(df.index)\n",
    "    correct = 0\n",
    "    for i, r in df.iterrows():\n",
    "        prediction = predict_author(r[\"text\"], matrices)\n",
    "        if prediction == r[\"author\"]:\n",
    "            count += 1\n",
    "    accuracy = correct/count\n",
    "    print(accuracy)\n",
    "        \n",
    "data = transition_matrix_by_author(DF)\n",
    "print(test(TEST_DF, data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
