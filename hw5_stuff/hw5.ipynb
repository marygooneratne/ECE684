{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fc86e6ec211ec41f78d9ab12f256e5586109e6cb3bfef37cec3aaebfaacb1b78"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import math\n",
    "from decimal import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in data\n",
    "def init_data(count=10000):\n",
    "    training_data = nltk.corpus.brown.tagged_sents(tagset='universal')[:count]\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating all the datasets\n",
    "def gen_data_sets(training_data):\n",
    "    tag_set = set()\n",
    "    word_set = set()\n",
    "    transition_dict = {}\n",
    "    tag_count = {}\n",
    "\n",
    "    for value in training_data:\n",
    "        previous = \"start\"\n",
    "        for data in value:\n",
    "            word_set.add(data[0].lower())\n",
    "            tag = data[1]\n",
    "            tag_set.add(tag)\n",
    "\n",
    "            if tag in tag_count:\n",
    "                tag_count[tag] += 1\n",
    "            else:\n",
    "                tag_count[tag] = 1\n",
    "\n",
    "            if (previous, tag) in transition_dict:\n",
    "                transition_dict[(previous, tag)] += 1\n",
    "                previous = tag\n",
    "            else:\n",
    "                transition_dict[(previous, tag)] = 1\n",
    "                previous = tag\n",
    "\n",
    "    return tag_set, word_set, transition_dict, tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to indices\n",
    "def build_word_map(word_set):\n",
    "    word_map = {'start': 0}\n",
    "    i = 1\n",
    "    for word in word_set:\n",
    "        if word in word_map:\n",
    "            continue\n",
    "        else:\n",
    "            word_map[word] = i\n",
    "            i += 1\n",
    "    word_map['undefined'] = len(word_map)\n",
    "\n",
    "    return word_map\n",
    "\n",
    "def build_tag_map(tag_set):\n",
    "    i = 1\n",
    "    tag_map = {'start': 0}\n",
    "    for tag in tag_set:\n",
    "        if tag in tag_map:\n",
    "            continue\n",
    "        else:\n",
    "            tag_map[tag] = i\n",
    "            i += 1\n",
    "\n",
    "    return tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building transition dictionary\n",
    "def gen_prob_dict(transition_dict, tag_set, tag_count, word_set):\n",
    "    prob_dict = {}\n",
    "    for key in transition_dict:\n",
    "        den = 0\n",
    "        val = key[0]\n",
    "        for key_2 in transition_dict:\n",
    "            if key_2[0] == val:\n",
    "                den += transition_dict[key_2]\n",
    "        prob_dict[key] = Decimal(transition_dict[key])/(den)\n",
    "    for tag in tag_set:\n",
    "        if (\"start\", tag) not in prob_dict:\n",
    "            prob_dict[(\"start\", tag)] = Decimal(\n",
    "                1) / Decimal(len(word_set) + tag_count[tag])\n",
    "    for tag1 in tag_set:\n",
    "        for tag2 in tag_set:\n",
    "            if (tag1, tag2) not in prob_dict:\n",
    "                prob_dict[(tag1, tag2)] = Decimal(\n",
    "                    1) / Decimal(len(word_set) + tag_count[tag1])\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating counts of words\n",
    "def gen_counts(training_data):\n",
    "    count_word = {}\n",
    "    for value in training_data:\n",
    "        for data in value:\n",
    "            word = data[0]\n",
    "            tag = data[1]\n",
    "            if (word, tag) in count_word:\n",
    "                count_word[(word, tag)] += 1\n",
    "            else:\n",
    "                count_word[(word, tag)] = 1\n",
    "    return count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the emission probabilities \n",
    "def gen_emission_prob(count_word, tag_count):\n",
    "    emission_prob_dict = {}\n",
    "    for key in count_word:\n",
    "        emission_prob_dict[key] = Decimal(count_word[key])/tag_count[key[1]]\n",
    "\n",
    "    return emission_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating matrices\n",
    "def gen_transition_matrix(tag_map, prob_dict):\n",
    "    transition_matrix = np.zeros((len(tag_map), len(tag_map)))\n",
    "    \n",
    "    for key, value in prob_dict.items():\n",
    "        i = tag_map[key[0]]\n",
    "        j = tag_map[key[1]]\n",
    "        transition_matrix[i, j] = value\n",
    "    return transition_matrix\n",
    "\n",
    "def gen_observation_matrix(tag_map, word_map, emission_prob_dict):\n",
    "    observation_matrix = np.zeros((len(tag_map), len(word_map)+1))\n",
    "\n",
    "    for key, value in emission_prob_dict.items():\n",
    "        i = tag_map[key[1]]\n",
    "        j = word_map[key[0].lower()]\n",
    "\n",
    "        observation_matrix[i][j] = value\n",
    "\n",
    "    random_model = 1/len(tag_map)\n",
    "    for tag in tag_map.keys():\n",
    "        i = tag_map[tag]\n",
    "        j = word_map['undefined']\n",
    "\n",
    "        observation_matrix[i][j] = random_model\n",
    "\n",
    "    return observation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in data and return the transition matrix, observation matrix, and the mappings of words to indices\n",
    "def load_matricies(training_data):\n",
    "    \n",
    "    tag_set, word_set, transition_dict, tag_count = gen_data_sets(training_data)\n",
    "    word_map = build_word_map(word_set)\n",
    "\n",
    "    tag_map = build_tag_map(tag_set)\n",
    "\n",
    "    prob_dict = gen_prob_dict(transition_dict, tag_set, tag_count, word_set)\n",
    "\n",
    "    word_count = gen_counts(training_data)\n",
    "\n",
    "    emission_prob_dict = gen_emission_prob(word_count, tag_count)\n",
    "\n",
    "\n",
    "    transition_matrix = gen_transition_matrix(tag_map, prob_dict)\n",
    "        \n",
    "    observation_matrix = gen_observation_matrix(tag_map, word_map, emission_prob_dict)\n",
    "\n",
    "    pi = transition_matrix[0]\n",
    "    \n",
    "    a = transition_matrix\n",
    "\n",
    "    b = observation_matrix\n",
    "\n",
    "    return pi, a, b, word_map, tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building path with viterbi\n",
    "def viterbi(obs, pi, a, b):\n",
    "    \n",
    "    num_states = np.shape(b)[0]\n",
    "    T = np.shape(obs)[0]\n",
    "\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    delta = np.zeros((num_states, T))\n",
    "    phi = np.zeros((num_states, T))\n",
    "\n",
    "    delta[:, 0] = pi * b[:, obs[0]]\n",
    "    phi[:, 0] = 0\n",
    "    for t in range(1, T):\n",
    "        for s in range(num_states):\n",
    "            delta[s, t] = np.max(delta[:, t-1] * a[:, s]) * b[s, obs[t]]\n",
    "            phi[s, t] = np.argmax(delta[:, t-1] * a[:, s])\n",
    "\n",
    "    states[T-1] = np.argmax(delta[:, T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        states[t] = phi[states[t+1], [t+1]]\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods to translate sentences to and from indices\n",
    "def sentence_to_idx(sentence, word_map):\n",
    "    idx_sentence = [0]\n",
    "    for wordtag in sentence:\n",
    "        word = wordtag[0]\n",
    "        try:\n",
    "            idx = word_map[word]\n",
    "        except:\n",
    "            idx = word_map['undefined']\n",
    "        idx_sentence.append(idx)\n",
    "    return idx_sentence\n",
    "\n",
    "\n",
    "def idx_to_sentence(states, tag_map):\n",
    "    final = []\n",
    "    for state in states:\n",
    "        for tag in tag_map.keys():\n",
    "            if tag_map[tag] == state:\n",
    "                final.append(tag)\n",
    "    return final[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run():\n",
    "    train_data = init_data()\n",
    "    pi, a, b, word_map, tag_map = load_matricies(train_data)\n",
    "    test = nltk.corpus.brown.tagged_sents(tagset='universal')[10150:10153]\n",
    "    for t in test:\n",
    "        print(t)\n",
    "        indices = sentence_to_idx(t,word_map)\n",
    "        states = viterbi(indices, pi, a, b)\n",
    "        print(idx_to_sentence(states, tag_map))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Those', 'DET'), ('coming', 'VERB'), ('from', 'ADP'), ('other', 'ADJ'), ('denominations', 'NOUN'), ('will', 'VERB'), ('welcome', 'VERB'), ('the', 'DET'), ('opportunity', 'NOUN'), ('to', 'PRT'), ('become', 'VERB'), ('informed', 'VERB'), ('.', '.')]\n['.', 'VERB', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'DET', 'NOUN', 'PRT', 'VERB', 'VERB', '.']\n\n[('The', 'DET'), ('preparatory', 'ADJ'), ('class', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('introductory', 'ADJ'), ('face-to-face', 'ADJ'), ('group', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('new', 'ADJ'), ('members', 'NOUN'), ('become', 'VERB'), ('acquainted', 'VERB'), ('with', 'ADP'), ('one', 'NUM'), ('another', 'DET'), ('.', '.')]\n['ADP', 'DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'DET', '.']\n\n[('It', 'PRON'), ('provides', 'VERB'), ('a', 'DET'), ('natural', 'ADJ'), ('transition', 'NOUN'), ('into', 'ADP'), ('the', 'DET'), ('life', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('local', 'ADJ'), ('church', 'NOUN'), ('and', 'CONJ'), ('its', 'DET'), ('organizations', 'NOUN'), ('.', '.')]\n['.', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'CONJ', 'DET', 'NOUN', '.']\n\n"
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}