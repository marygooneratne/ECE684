{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fc86e6ec211ec41f78d9ab12f256e5586109e6cb3bfef37cec3aaebfaacb1b78"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import math\n",
    "from decimal import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = nltk.corpus.brown.tagged_sents(tagset='universal')[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = set()\n",
    "word_set = set()\n",
    "transition_dict = {}\n",
    "tag_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in training_data:\n",
    "    previous = \"start\"\n",
    "    for data in value:\n",
    "        word_set.add(data[0].lower())\n",
    "        tag = data[1]\n",
    "        tag_list.add(tag)\n",
    "\n",
    "        if tag in tag_count:\n",
    "            tag_count[tag] += 1\n",
    "        else:\n",
    "            tag_count[tag] = 1\n",
    "\n",
    "        if (previous, tag) in transition_dict:\n",
    "            transition_dict[(previous, tag)] += 1\n",
    "            previous = tag\n",
    "        else:\n",
    "            transition_dict[(previous, tag)] = 1\n",
    "            previous = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = {'start': 0}\n",
    "i = 1\n",
    "for word in word_set:\n",
    "    if word in word_map:\n",
    "        continue\n",
    "    else:\n",
    "        word_map[word] = i\n",
    "        i += 1\n",
    "word_map['undefined'] = len(word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "tag_map = {'start': 0}\n",
    "for tag in tag_list:\n",
    "    if tag in tag_map:\n",
    "        continue\n",
    "    else:\n",
    "        tag_map[tag] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = transition_dict\n",
    "prob_dict = {}\n",
    "for key in count_dict:\n",
    "    den = 0\n",
    "    val = key[0]\n",
    "    for key_2 in count_dict:\n",
    "        if key_2[0] == val:\n",
    "            den += count_dict[key_2]\n",
    "    prob_dict[key] = Decimal(count_dict[key])/(den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob = prob_dict\n",
    "for tag in tag_list:\n",
    "    if (\"start\", tag) not in transition_prob:\n",
    "        transition_prob[(\"start\", tag)] = Decimal(\n",
    "            1) / Decimal(len(word_set) + tag_count[tag])\n",
    "for tag1 in tag_list:\n",
    "    for tag2 in tag_list:\n",
    "        if (tag1, tag2) not in transition_prob:\n",
    "            transition_prob[(tag1, tag2)] = Decimal(\n",
    "                1) / Decimal(len(word_set) + tag_count[tag1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_word = {}\n",
    "for value in training_data:\n",
    "    for data in value:\n",
    "        word = data[0]\n",
    "        tag = data[1]\n",
    "        if (word, tag) in count_word:\n",
    "            count_word[(word, tag)] += 1\n",
    "        else:\n",
    "            count_word[(word, tag)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = count_word\n",
    "emission_prob_dict = {}\n",
    "for key in word_count:\n",
    "    emission_prob_dict[key] = Decimal(\n",
    "        word_count[key])/tag_count[key[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.zeros((len(tag_map), len(tag_map)))\n",
    "# print(transition_prob)\n",
    "for key, value in transition_prob.items():\n",
    "    i = tag_map[key[0]]\n",
    "    j = tag_map[key[1]]\n",
    "    transition_matrix[i, j] = value\n",
    "# print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_matrix = np.zeros((len(tag_map), len(word_map)+1))\n",
    "\n",
    "for key, value in emission_prob_dict.items():\n",
    "    i = tag_map[key[1]]\n",
    "    j = word_map[key[0].lower()]\n",
    "\n",
    "    observation_matrix[i][j] = value\n",
    "random_model = 1/len(tag_map)\n",
    "for tag in tag_map.keys():\n",
    "    i = tag_map[tag]\n",
    "    j = word_map['undefined']\n",
    "\n",
    "    observation_matrix[i][j] = random_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs, pi, a, b):\n",
    "    print(obs)\n",
    "    # obs.append(0)\n",
    "    # obs_plain = []\n",
    "    # for word in tagset[0]:\n",
    "    #     obs_plain.append(word)\n",
    "    #     obs.append(word_map[word[0].lower()])\n",
    "    # print(obs_plain)\n",
    "    nStates = np.shape(b)[0]\n",
    "    T = np.shape(obs)[0]\n",
    "\n",
    "    # init blank path\n",
    "    path = np.zeros(T, dtype=int)\n",
    "    # delta --> highest probability of any path that reaches state i\n",
    "    delta = np.zeros((nStates, T))\n",
    "    # phi --> argmax by time step for each state\n",
    "    phi = np.zeros((nStates, T))\n",
    "\n",
    "    # init delta and phi\n",
    "    delta[:, 0] = pi * b[:, obs[0]]\n",
    "    phi[:, 0] = 0\n",
    "    for t in range(1, T):\n",
    "        for s in range(nStates):\n",
    "            delta[s, t] = np.max(delta[:, t-1] * a[:, s]) * b[s, obs[t]]\n",
    "            phi[s, t] = np.argmax(delta[:, t-1] * a[:, s])\n",
    "\n",
    "    path[T-1] = np.argmax(delta[:, T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        path[t] = phi[path[t+1], [t+1]]\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0\n[[0.00000000e+00 5.49000000e-02 1.20700000e-01 4.10000000e-02\n  1.73000000e-02 6.50000000e-02 3.07000000e-02 5.00000000e-04\n  2.40300000e-01 1.13400000e-01 1.96500000e-01 4.22000000e-02\n  7.75000000e-02]\n [0.00000000e+00 4.53309157e-04 6.76941674e-02 1.60320338e-01\n  1.94922937e-02 2.29676639e-02 2.35720762e-02 3.02206105e-04\n  1.57147174e-01 5.25838622e-02 2.89815654e-01 1.17558175e-01\n  8.80930795e-02]\n [0.00000000e+00 1.28875469e-03 1.89262832e-02 3.85153546e-02\n  3.90308565e-02 1.13778629e-02 1.21879373e-02 3.68215627e-04\n  4.43147507e-01 4.96722881e-02 2.87281832e-01 8.45791295e-02\n  1.36239782e-02]]\n[[0.         0.         0.         ... 0.         0.         0.07692308]\n [0.         0.         0.         ... 0.         0.         0.07692308]\n [0.         0.         0.         ... 0.         0.         0.07692308]]\n"
    }
   ],
   "source": [
    "pi = transition_matrix[0]\n",
    "print(sum(pi))\n",
    "a = transition_matrix\n",
    "print(a[0:3])\n",
    "b = observation_matrix\n",
    "print(b[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentence(sentence):\n",
    "    idx_sentence = [0]\n",
    "    for wordtag in sentence:\n",
    "        word = wordtag[0]\n",
    "        try:\n",
    "            idx = word_map[word]\n",
    "        except:\n",
    "            idx = word_map['undefined']\n",
    "        idx_sentence.append(idx)\n",
    "    return idx_sentence\n",
    "\n",
    "\n",
    "def dec_sentence(states):\n",
    "    final = []\n",
    "    for state in states:\n",
    "        for tag in tag_map.keys():\n",
    "            if tag_map[tag] == state:\n",
    "                final.append(tag)\n",
    "    return final[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Those', 'DET'), ('coming', 'VERB'), ('from', 'ADP'), ('other', 'ADJ'), ('denominations', 'NOUN'), ('will', 'VERB'), ('welcome', 'VERB'), ('the', 'DET'), ('opportunity', 'NOUN'), ('to', 'PRT'), ('become', 'VERB'), ('informed', 'VERB'), ('.', '.')]\n[0, 21248, 10975, 8424, 1556, 21248, 10254, 18107, 17932, 20266, 12995, 3987, 6269, 15454]\n['.', 'VERB', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'DET', 'NOUN', 'PRT', 'VERB', 'VERB', '.']\n\n[('The', 'DET'), ('preparatory', 'ADJ'), ('class', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('introductory', 'ADJ'), ('face-to-face', 'ADJ'), ('group', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('new', 'ADJ'), ('members', 'NOUN'), ('become', 'VERB'), ('acquainted', 'VERB'), ('with', 'ADP'), ('one', 'NUM'), ('another', 'DET'), ('.', '.')]\n[0, 21248, 21248, 19584, 3974, 1515, 21248, 21248, 8717, 6164, 9207, 12845, 1975, 3987, 10053, 13650, 20195, 15420, 15454]\n['ADP', 'DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'DET', '.']\n\n[('It', 'PRON'), ('provides', 'VERB'), ('a', 'DET'), ('natural', 'ADJ'), ('transition', 'NOUN'), ('into', 'ADP'), ('the', 'DET'), ('life', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('local', 'ADJ'), ('church', 'NOUN'), ('and', 'CONJ'), ('its', 'DET'), ('organizations', 'NOUN'), ('.', '.')]\n[0, 21248, 15478, 17696, 8902, 14696, 9962, 17932, 15894, 19225, 17932, 13316, 2350, 16864, 6195, 998, 15454]\n['.', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'CONJ', 'DET', 'NOUN', '.']\n\n"
    }
   ],
   "source": [
    "test = nltk.corpus.brown.tagged_sents(tagset='universal')[10150:10153]\n",
    "\n",
    "for t in test:\n",
    "    print(t)\n",
    "    idx_sentence = build_sentence(t)\n",
    "    vt = viterbi(idx_sentence, pi, a, b)\n",
    "    print(dec_sentence(vt))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}